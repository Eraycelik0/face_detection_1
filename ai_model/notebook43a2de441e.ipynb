{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":37705,"sourceType":"datasetVersion","datasetId":29561}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.utils.class_weight import compute_class_weight\nimport matplotlib.pyplot as plt\n\n# Hiperparametreler\nIMAGE_SIZE = (224, 224)\nBATCH_SIZE = 64\nEPOCHS = 10\nLEARNING_RATE = 0.0001\nIMAGE_DIR = \"/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba\"\nATTR_PATH = \"/kaggle/input/celeba-dataset/list_attr_celeba.csv\"\nPARTITION_PATH = \"/kaggle/input/celeba-dataset/list_eval_partition.csv\"\n\n# Veri setini yükleme ve işleme\nattr_df = pd.read_csv(ATTR_PATH)\npartition_df = pd.read_csv(PARTITION_PATH)\n\n# Smiling etiketini işaretleme\nattr_df[\"smiling\"] = attr_df[\"Smiling\"].apply(lambda x: \"smiling\" if x == 1 else \"not_smiling\")\n\n# Eğitim ve doğrulama veri çerçeveleri\npartition_df = partition_df.rename(columns={\"image_id\": \"image_id\", \"partition\": \"partition\"})\ntrain_df = partition_df[partition_df[\"partition\"] == 0]\nval_df = partition_df[partition_df[\"partition\"] == 1]\n\ntrain_df = train_df.merge(attr_df[[\"image_id\", \"smiling\"]], on=\"image_id\")\nval_df = val_df.merge(attr_df[[\"image_id\", \"smiling\"]], on=\"image_id\")\n\n# Veri dengesini kontrol et\ntrain_class_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(train_df[\"smiling\"]),\n    y=train_df[\"smiling\"]\n)\nclass_weights = dict(enumerate(train_class_weights))\n\nprint(f\"Class Weights: {class_weights}\")\n\n# Veri artırma\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0/255,\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n)\nval_datagen = ImageDataGenerator(rescale=1.0/255)\n\n# Veri jeneratörleri\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df,\n    directory=IMAGE_DIR,\n    x_col=\"image_id\",\n    y_col=\"smiling\",\n    target_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode=\"binary\"\n)\n\nval_generator = val_datagen.flow_from_dataframe(\n    val_df,\n    directory=IMAGE_DIR,\n    x_col=\"image_id\",\n    y_col=\"smiling\",\n    target_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode=\"binary\"\n)\n\n# Modeli oluştur\nbase_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\nbase_model.trainable = False  # İlk olarak önceden eğitilmiş ağı dondur\n\nmodel = Sequential([\n    base_model,\n    GlobalAveragePooling2D(),\n    Dense(256, activation=\"relu\"),\n    Dropout(0.5),\n    Dense(1, activation=\"sigmoid\")\n])\n\n# Modeli derle\nmodel.compile(\n    optimizer=Adam(learning_rate=LEARNING_RATE),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\n# Callbacks\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint(\n        \"/kaggle/working/best_model.keras\",\n        save_best_only=True,\n        monitor=\"val_accuracy\",\n        mode=\"max\"\n    ),\n    tf.keras.callbacks.EarlyStopping(\n        monitor=\"val_accuracy\",\n        patience=5,\n        restore_best_weights=True\n    ),\n    tf.keras.callbacks.ReduceLROnPlateau(\n        monitor=\"val_loss\",\n        factor=0.5,\n        patience=2,\n        min_lr=1e-6\n    )\n]\n\n# Modeli eğit\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=EPOCHS,\n    callbacks=callbacks,\n    class_weight=class_weights\n)\n\n# Temel modeli yeniden eğitme\nbase_model.trainable = True\n\n# Yalnızca belirli katmanları yeniden eğit\nfor layer in base_model.layers[:100]:\n    layer.trainable = False\n\n# Modeli yeniden eğit\nmodel.compile(\n    optimizer=Adam(learning_rate=LEARNING_RATE / 10),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nhistory_fine_tune = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=EPOCHS // 2,\n    callbacks=callbacks,\n    class_weight=class_weights\n)\n\n# Modeli değerlendir\nloss, accuracy = model.evaluate(val_generator)\nprint(f\"Doğrulama Kaybı: {loss}\")\nprint(f\"Doğrulama Doğruluğu: {accuracy}\")\n\n# Modeli kaydet\nmodel.save(\"/kaggle/working/final_model.keras\")\n\n# Eğitim geçmişini görselleştirme\nplt.figure(figsize=(12, 6))\n\n# Doğruluk\nplt.subplot(1, 2, 1)\nplt.plot(history.history[\"accuracy\"], label=\"Eğitim Doğruluğu\")\nplt.plot(history.history[\"val_accuracy\"], label=\"Doğrulama Doğruluğu\")\nplt.title(\"Model Doğruluğu\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\n\n# Kayıp\nplt.subplot(1, 2, 2)\nplt.plot(history.history[\"loss\"], label=\"Eğitim Kaybı\")\nplt.plot(history.history[\"val_loss\"], label=\"Doğrulama Kaybı\")\nplt.title(\"Model Kaybı\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\nplt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:47:55.226269Z","iopub.execute_input":"2024-12-25T08:47:55.226639Z","execution_failed":"2024-12-25T20:47:33.422Z"}},"outputs":[{"name":"stdout","text":"Class Weights: {0: 0.9609753217617192, 1: 1.042328381147541}\nFound 162770 validated image filenames belonging to 2 classes.\nFound 19867 validated image filenames belonging to 2 classes.\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2544/2544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5277s\u001b[0m 2s/step - accuracy: 0.6989 - loss: 0.5704 - val_accuracy: 0.7900 - val_loss: 0.4512 - learning_rate: 1.0000e-04\nEpoch 2/10\n\u001b[1m2544/2544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4879s\u001b[0m 2s/step - accuracy: 0.7712 - loss: 0.4776 - val_accuracy: 0.7960 - val_loss: 0.4394 - learning_rate: 1.0000e-04\nEpoch 3/10\n\u001b[1m2544/2544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4923s\u001b[0m 2s/step - accuracy: 0.7810 - loss: 0.4626 - val_accuracy: 0.7998 - val_loss: 0.4290 - learning_rate: 1.0000e-04\nEpoch 4/10\n\u001b[1m2544/2544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4900s\u001b[0m 2s/step - accuracy: 0.7859 - loss: 0.4531 - val_accuracy: 0.8044 - val_loss: 0.4248 - learning_rate: 1.0000e-04\nEpoch 5/10\n\u001b[1m2544/2544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4891s\u001b[0m 2s/step - accuracy: 0.7915 - loss: 0.4467 - val_accuracy: 0.8067 - val_loss: 0.4201 - learning_rate: 1.0000e-04\nEpoch 6/10\n\u001b[1m2544/2544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4785s\u001b[0m 2s/step - accuracy: 0.7901 - loss: 0.4465 - val_accuracy: 0.8084 - val_loss: 0.4187 - learning_rate: 1.0000e-04\nEpoch 7/10\n\u001b[1m2544/2544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4836s\u001b[0m 2s/step - accuracy: 0.7924 - loss: 0.4431 - val_accuracy: 0.8085 - val_loss: 0.4160 - learning_rate: 1.0000e-04\nEpoch 8/10\n\u001b[1m2544/2544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4849s\u001b[0m 2s/step - accuracy: 0.7945 - loss: 0.4376 - val_accuracy: 0.8128 - val_loss: 0.4111 - learning_rate: 1.0000e-04\nEpoch 9/10\n\u001b[1m1870/2544\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m19:18\u001b[0m 2s/step - accuracy: 0.7952 - loss: 0.4378","output_type":"stream"}],"execution_count":null}]}